{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This and following series of notebooks dive into the Transformers & Huggingface philosophy and how things are built. \n",
    "\n",
    "https://huggingface.co/docs/transformers/philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy & Fast to use\n",
    "\n",
    "> 3 Classes for any models: configuration, models and preprocessor like tokenizer(NLP), image_procesor(vision), feature_extractor(audio) and processor for multi-modal. All intialized using .from_pretrained() method. The model data is pulled from huggingface_hub. \n",
    "\n",
    "> pipeline() to do inference and trainer() to train the models\n",
    "\n",
    "### Provide SOTA models that are close in performance to the original models:\n",
    "\n",
    "> One example of each architecture is provided, that reproduces the results of the model authors. \n",
    "\n",
    "> The code is **close** to original, meaning some code may not be pytorchic\n",
    "\n",
    "> Provides API access to **Full Hidden States** and **attention weights** of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a5727a399b4168b2e401e878d11ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825068a7487942559791201d2654447b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3eb66134fe14731894ac778b0a0ce05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78f39b5935b42799f3aa0ff35b522fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at the attention masks in Transformers\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_a = \"This is a sentence of 3 words\"\n",
    "seq_b = \"This is a sentence of more than 3 words, providing lot more information\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_a = tokenizer(seq_a)['input_ids']\n",
    "encode_b = tokenizer(seq_b)['input_ids']\n",
    "len(encode_a), len(encode_b)  # (9, 16)  # Have different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1188, 1110, 170, 5650, 1104, 124, 1734, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How the tokenizer output looks, with a single input\n",
    "tokenizer(seq_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1188, 1110, 170, 5650, 1104, 124, 1734, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1188, 1110, 170, 5650, 1104, 1167, 1190, 124, 1734, 117, 3558, 1974, 1167, 1869, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([seq_a, seq_b], padding=True) # The tokens and attention masks are padded where required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer([seq_a, seq_b], padding=True) # The tokens and attention masks are padded where required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] This is a sentence of 3 words [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some interestin / important terms:\n",
    "\n",
    "backbone: model / network that outputs raw hidden states. This is connected to a **head**. There are different \"head\" for different tasks. \n",
    "    \n",
    "    > LM Head\n",
    "    > DoubleHeads\n",
    "    > Question Answering\n",
    "    > Sequence Classification\n",
    "    > Token Classification\n",
    "\n",
    "CTC / connectionist temporal algorithm: Model learns without exactly knowing how the inputs and outputs are aligned. Its used in **speech recognition**\n",
    "\n",
    "convolution: NN Layer, where the inputs are multiplied element-wise by a smaller kernel-matrix & summed up into new matrix\n",
    "\n",
    "decoder models are auto-regressive, as they learn to predict the next words from the dataset of masked sentences. \n",
    "\n",
    "encoder models are auto-encoding, which uses Masked Language Modeling and embedding to create numerical representation\n",
    "\n",
    "labels are optional argument which can be passed in order for the model to compute loss itself. The base models don't accept labels, as they just output featurers\n",
    "\n",
    "Position_ids are required by Transformers to identify the location of a particular tokens. There are many positional embedding like sinusoidal and relative embeddings. The position must be between [0, config.max_position_embeddings - 1]\n",
    "\n",
    "self-supervised learning, is the process of creating its own learning objectives and learn from **unlabled data**. Masked language modelling is one such self-supervised learning.\n",
    "\n",
    "ZeRO : Zero Redundancy Optimizer, which is a kind of tensor sharding for parallel operation. The shards are reconstructed during forward and backward computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain and the models segregated into different architectures\n",
    "\n",
    "computer_vision = {\n",
    "    \"encoder\": ['ViT','Swin', 'SegFormer', 'BEiT'],\n",
    "    \"decoder\": ['ImageGPT'],\n",
    "    \"encoder-decoder\": ['DETR'],\n",
    "    \"convolution\": ['ConvNeXT']\n",
    "}\n",
    "\n",
    "NLP = {\n",
    "    \"encoder\": [\"BERT\", \"RoBERTa\", \"ALBERT\", \"DistillBERT\", \"DeBERTa\", \"Longformer\",],\n",
    "    \"decoder\": [\"GPT-2\", \"XLNet\", \"GPT-J\", \"OPT\", \"BLOOM\"],\n",
    "    \"encoder-decoder\": [\"BART\", \"Pegasus\", \"T5\", ],\n",
    "}\n",
    "\n",
    "Audio = {\n",
    "    \"encoder\": [\"Wav2Vec2\", \"Hubert\"],\n",
    "    \"encoder-decoder\": [\"Speech2Text\", \"Whisper\"]\n",
    "}\n",
    "\n",
    "MultiM = {\n",
    "    \"encoder\": [\"VisualBERT\", \"ViLT\", \"CLiP\", \"OWL-ViT\"],\n",
    "    \"encoder-decoder\": [\"TrOCR\", \"Donut\"]\n",
    "}\n",
    "\n",
    "Reinforcement = {\n",
    "    \"decoder\": [\"Trajectory transformer\", \"Decision transformer\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizers\n",
    "# moving from rule based, word level to char level and settling on subword algorithm.\n",
    "# subword allows for reasonable vocabulary size, and allows to learn the representation\n",
    "Rule_based = ['spacy', 'moses', 'XLM', 'FlauBERT',]\n",
    "\n",
    "sub_word = ['Byte-pair-encoding', 'WordPiece', 'Unigram', 'SentencePiece']\n",
    "# Need to locate the data on models and their respective tokenisation algorithms\n",
    "\n",
    "space_based = [\"GPT-2\", \"RoBERTa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_algos = {\n",
    "    \"byte_pair\": {\n",
    "        \"base\": ['GPT'],\n",
    "        \"byte_level\": ['GPT-2'],\n",
    "        \"intro\": \"https://arxiv.org/abs/1508.07909\"\n",
    "    },\n",
    "    \"WordPiece\":{\n",
    "        \"base\": ['BERT', 'DistilBERT', 'Electra'],\n",
    "        \"intro\": \"https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf\"\n",
    "    },\n",
    "    \"Unigram\": {\n",
    "        \"base\": [],\n",
    "        \"intro\": \"https://arxiv.org/pdf/1804.10959.pdf\"\n",
    "    },\n",
    "    \"SentencePiece\":{\n",
    "        \"base\": [\"XLM\", \"ALBERT\", \"XLNET\", \"Marian\", \"T5\"],\n",
    "        \"intro\": \"https://arxiv.org/pdf/1808.06226.pdf\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'great', 'N', '##vid', '##ia', '40', '##70', 'GP', '##U']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working of BertTokenizer\n",
    "tokens = tokenizer.tokenize(\"I have a great Nvidia 4070 GPU\")\n",
    "tokens  \n",
    "# '##' signifies the word can be attached with earlier token in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bab20182dd04f3f8f3bf022fc243f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b988ed8e54ac09c287e3ab53a79b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e75a278dc343acbc412b93b0766fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['▁Do',\n",
       " '▁you',\n",
       " '▁love',\n",
       " '▁your',\n",
       " '▁G',\n",
       " 'PU',\n",
       " '▁very',\n",
       " '▁much',\n",
       " '?',\n",
       " '▁I',\n",
       " '▁do',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "xlnet_tokenizer.tokenize(\"Do you love your GPU very much? I do.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT has a vocabulary size of 40,478 since they have 478 base characters and chose to stop training after 40,000 merges.\n",
    "\n",
    "# GPT-2 has a vocabulary size of 50,257, which corresponds to the 256 bytes base tokens, a special end-of-text token and the symbols learned with 50,000 merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
