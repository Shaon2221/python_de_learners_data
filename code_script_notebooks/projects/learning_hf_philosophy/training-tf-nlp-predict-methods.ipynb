{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Motivation:** \n\nDuring the practice session with tokenizers, and various Models of AutoModel Instances, I got stuck when trying to convert the raw model output using the tokenizer.decode(). Which made me realize that, depending on the model head, decoding strategy will differ.  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    AutoModelForSequenceClassification,\n    AutoModelForTokenClassification,\n    AutoModelForMaskedLM,\n    AutoModelForQuestionAnswering, \n    AutoModelForMultipleChoice\n)\nimport torch\n# The above classes provide different heads to the underlying model, ","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:46:18.652023Z","iopub.execute_input":"2024-02-08T05:46:18.652567Z","iopub.status.idle":"2024-02-08T05:46:18.659280Z","shell.execute_reply.started":"2024-02-08T05:46:18.652530Z","shell.execute_reply":"2024-02-08T05:46:18.658052Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"task_arch = {\n    \"text_classification\":{\n        \"architectures\":['ALBERT','BART',\n 'BERT',\n 'BigBird',\n 'BigBird-Pegasus',\n 'BioGpt',\n 'BLOOM',\n 'CamemBERT',\n 'CANINE',\n 'CodeLlama',\n 'ConvBERT',\n 'CTRL',\n 'Data2VecText',\n 'DeBERTa',\n 'DeBERTa-v2',\n 'DistilBERT',\n 'ELECTRA',\n 'ERNIE',\n 'ErnieM',\n 'ESM',\n 'Falcon',\n 'FlauBERT',\n 'FNet',\n 'Funnel Transformer',\n 'GPT-Sw3',\n 'OpenAI GPT-2',\n 'GPTBigCode',\n 'GPT Neo',\n 'GPT NeoX',\n 'GPT-J',\n 'I-BERT',\n 'LayoutLM',\n 'LayoutLMv2',\n 'LayoutLMv3',\n 'LED',\n 'LiLT',\n 'LLaMA',\n 'Longformer',\n 'LUKE',\n 'MarkupLM',\n 'mBART',\n 'MEGA',\n 'Megatron-BERT',\n 'Mistral',\n 'Mixtral',\n 'MobileBERT',\n 'MPNet',\n 'MPT',\n 'MRA',\n 'MT5',\n 'MVP',\n 'Nezha',\n 'Nyströmformer',\n 'OpenLlama',\n 'OpenAI GPT',\n 'OPT',\n 'Perceiver',\n 'Persimmon',\n 'Phi',\n 'PLBart',\n 'QDQBert',\n 'Qwen2',\n 'Reformer',\n 'RemBERT',\n 'RoBERTa',\n 'RoBERTa-PreLayerNorm',\n 'RoCBert',\n 'RoFormer',\n 'SqueezeBERT',\n 'T5',\n 'TAPAS',\n 'Transformer-XL',\n 'UMT5',\n 'XLM',\n 'XLM-RoBERTa',\n 'XLM-RoBERTa-XL',\n 'XLNet',\n 'X-MOD',\n 'YOSO'],\n        \"AutoModelClass\": \"AutoModelForSequenceClassification\",\n        \"dataset\": \"imdb\",\n        \"model_used\": \"distilbert-base-uncased\",\n    },\n    \"token_classification\":{\n        \"architectures\":['ALBERT',\n 'BERT',\n 'BigBird',\n 'BioGpt',\n 'BLOOM',\n 'BROS',\n 'CamemBERT',\n 'CANINE',\n 'ConvBERT',\n 'Data2VecText',\n 'DeBERTa',\n 'DeBERTa-v2',\n 'DistilBERT',\n 'ELECTRA',\n 'ERNIE',\n 'ErnieM',\n 'ESM',\n 'Falcon',\n 'FlauBERT',\n 'FNet',\n 'Funnel Transformer',\n 'GPT-Sw3',\n 'OpenAI GPT-2',\n 'GPTBigCode',\n 'GPT Neo',\n 'GPT NeoX',\n 'I-BERT',\n 'LayoutLM',\n 'LayoutLMv2',\n 'LayoutLMv3',\n 'LiLT',\n 'Longformer',\n 'LUKE',\n 'MarkupLM',\n 'MEGA',\n 'Megatron-BERT',\n 'MobileBERT',\n 'MPNet',\n 'MPT',\n 'MRA',\n 'MT5',\n 'Nezha',\n 'Nyströmformer',\n 'Phi',\n 'QDQBert',\n 'RemBERT',\n 'RoBERTa',\n 'RoBERTa-PreLayerNorm',\n 'RoCBert',\n 'RoFormer',\n 'SqueezeBERT',\n 'T5',\n 'UMT5',\n 'XLM',\n 'XLM-RoBERTa',\n 'XLM-RoBERTa-XL',\n 'XLNet',\n 'X-MOD',\n 'YOSO'],\n        \"AutoModelClass\": \"AutoModelForTokenClassification\",\n        \"dataset\": \"wnut_17\",\n        \"model_used\": \"distilbert-base-uncased\",\n    },\n    \"question_answering\":{\n        \"architectures\":['ALBERT',\n 'BART',\n 'BERT',\n 'BigBird',\n 'BigBird-Pegasus',\n 'BLOOM',\n 'CamemBERT',\n 'CANINE',\n 'ConvBERT',\n 'Data2VecText',\n 'DeBERTa',\n 'DeBERTa-v2',\n 'DistilBERT',\n 'ELECTRA',\n 'ERNIE',\n 'ErnieM',\n 'Falcon',\n 'FlauBERT',\n 'FNet',\n 'Funnel Transformer',\n 'OpenAI GPT-2',\n 'GPT Neo',\n 'GPT NeoX',\n 'GPT-J',\n 'I-BERT',\n 'LayoutLMv2',\n 'LayoutLMv3',\n 'LED',\n 'LiLT',\n 'LLaMA',\n 'Longformer',\n 'LUKE',\n 'LXMERT',\n 'MarkupLM',\n 'mBART',\n 'MEGA',\n 'Megatron-BERT',\n 'MobileBERT',\n 'MPNet',\n 'MPT',\n 'MRA',\n 'MT5',\n 'MVP',\n 'Nezha',\n 'Nyströmformer',\n 'OPT',\n 'QDQBert',\n 'Reformer',\n 'RemBERT',\n 'RoBERTa',\n 'RoBERTa-PreLayerNorm',\n 'RoCBert',\n 'RoFormer',\n 'Splinter',\n 'SqueezeBERT',\n 'T5',\n 'UMT5',\n 'XLM',\n 'XLM-RoBERTa',\n 'XLM-RoBERTa-XL',\n 'XLNet',\n 'X-MOD',\n 'YOSO'],\n        \"AutoModelClass\": \"AutoModelForQuestionAnswering\",\n        \"dataset\": \"squad\",\n        \"model_used\": \"distilbert-base-uncased\",\n    },\n    \"causal_lm\":{\n        \"architectures\": ['BART',\n 'BERT',\n 'Bert Generation',\n 'BigBird',\n 'BigBird-Pegasus',\n 'BioGpt',\n 'Blenderbot',\n 'BlenderbotSmall',\n 'BLOOM',\n 'CamemBERT',\n 'CodeLlama',\n 'CodeGen',\n 'CPM-Ant',\n 'CTRL',\n 'Data2VecText',\n 'ELECTRA',\n 'ERNIE',\n 'Falcon',\n 'Fuyu',\n 'GIT',\n 'GPT-Sw3',\n 'OpenAI GPT-2',\n 'GPTBigCode',\n 'GPT Neo',\n 'GPT NeoX',\n 'GPT NeoX Japanese',\n 'GPT-J',\n 'LLaMA',\n 'Marian',\n 'mBART',\n 'MEGA',\n 'Megatron-BERT',\n 'Mistral',\n 'Mixtral',\n 'MPT',\n 'MusicGen',\n 'MVP',\n 'OpenLlama',\n 'OpenAI GPT',\n 'OPT',\n 'Pegasus',\n 'Persimmon',\n 'Phi',\n 'PLBart',\n 'ProphetNet',\n 'QDQBert',\n 'Qwen2',\n 'Reformer',\n 'RemBERT',\n 'RoBERTa',\n 'RoBERTa-PreLayerNorm',\n 'RoCBert',\n 'RoFormer',\n 'RWKV',\n 'Speech2Text2',\n 'Transformer-XL',\n 'TrOCR',\n 'Whisper',\n 'XGLM',\n 'XLM',\n 'XLM-ProphetNet',\n 'XLM-RoBERTa',\n 'XLM-RoBERTa-XL',\n 'XLNet',\n 'X-MOD'],\n        \"AutoModelClass\":\"AutoModelForCausalLM\",\n        \"dataset\": \"eli5_category\",\n        \"model_used\": \"distilgpt2\",\n    },\n    \"masked_lm\":{\n        \"architectures\": ['ALBERT',\n 'BART',\n 'BERT',\n 'BigBird',\n 'CamemBERT',\n 'ConvBERT',\n 'Data2VecText',\n 'DeBERTa',\n 'DeBERTa-v2',\n 'DistilBERT',\n 'ELECTRA',\n 'ERNIE',\n 'ESM',\n 'FlauBERT',\n 'FNet',\n 'Funnel Transformer',\n 'I-BERT',\n 'LayoutLM',\n 'Longformer',\n 'LUKE',\n 'mBART',\n 'MEGA',\n 'Megatron-BERT',\n 'MobileBERT',\n 'MPNet',\n 'MRA',\n 'MVP',\n 'Nezha',\n 'Nyströmformer',\n 'Perceiver',\n 'QDQBert',\n 'Reformer',\n 'RemBERT',\n 'RoBERTa',\n 'RoBERTa-PreLayerNorm',\n 'RoCBert',\n 'RoFormer',\n 'SqueezeBERT',\n 'TAPAS',\n 'Wav2Vec2',\n 'XLM',\n 'XLM-RoBERTa',\n 'XLM-RoBERTa-XL',\n 'X-MOD',\n 'YOSO'],\n        \"AutoModelClass\": \"AutoModelForMaskedLM\",\n        \"dataset\": \"eli-5\",\n        \"model_used\": \"distilroberta-base\",\n    },\n    \"translation\":{\n        \"architectures\": ['BART',\n 'BigBird-Pegasus',\n 'Blenderbot',\n 'BlenderbotSmall',\n 'Encoder decoder',\n 'FairSeq Machine-Translation',\n 'GPTSAN-japanese',\n 'LED',\n 'LongT5',\n 'M2M100',\n 'Marian',\n 'mBART',\n 'MT5',\n 'MVP',\n 'NLLB',\n 'NLLB-MOE',\n 'Pegasus',\n 'PEGASUS-X',\n 'PLBart',\n 'ProphetNet',\n 'SeamlessM4T',\n 'SeamlessM4Tv2',\n 'SwitchTransformers',\n 'T5',\n 'UMT5',\n 'XLM-ProphetNet'],\n        \"AutoModelClass\": \"AutoModelForSeq2SeqLM\",\n        \"dataset\": \"opus_books\",\n        \"model_used\": \"t5-small\",\n    },\n    \"summarization\":{\n        \"architectures\": ['BART',\n 'BigBird-Pegasus',\n 'Blenderbot',\n 'BlenderbotSmall',\n 'Encoder decoder',\n 'FairSeq Machine-Translation',\n 'GPTSAN-japanese',\n 'LED',\n 'LongT5',\n 'M2M100',\n 'Marian',\n 'mBART',\n 'MT5',\n 'MVP',\n 'NLLB',\n 'NLLB-MOE',\n 'Pegasus',\n 'PEGASUS-X',\n 'PLBart',\n 'ProphetNet',\n 'SeamlessM4T',\n 'SeamlessM4Tv2',\n 'SwitchTransformers',\n 'T5',\n 'UMT5',\n 'XLM-ProphetNet'],\n        \"AutoModelClass\": \"AutoModelForSeq2SeqLM\",\n        \"dataset\": \"billsum\",\n        \"model_used\": \"t5-small\",\n    },\n    \"multiple_choice\":{\n        \"architectures\": ['ALBERT',\n 'BERT',\n 'BigBird',\n 'CamemBERT',\n 'CANINE',\n 'ConvBERT',\n 'Data2VecText',\n 'DeBERTa-v2',\n 'DistilBERT',\n 'ELECTRA',\n 'ERNIE',\n 'ErnieM',\n 'FlauBERT',\n 'FNet',\n 'Funnel Transformer',\n 'I-BERT',\n 'Longformer',\n 'LUKE',\n 'MEGA',\n 'Megatron-BERT',\n 'MobileBERT',\n 'MPNet',\n 'MRA',\n 'Nezha',\n 'Nyströmformer',\n 'QDQBert',\n 'RemBERT',\n 'RoBERTa',\n 'RoBERTa-PreLayerNorm',\n 'RoCBert',\n 'RoFormer',\n 'SqueezeBERT',\n 'XLM',\n 'XLM-RoBERTa',\n 'XLM-RoBERTa-XL',\n 'XLNet',\n 'X-MOD',\n 'YOSO'],\n        \"AutoModelClass\": \"AutoModelForMultipleChoice\",\n        \"dataset\": \"swag\",\n        \"model_used\": \"bert-base-uncased\",\n    },\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:42:23.373787Z","iopub.execute_input":"2024-02-08T05:42:23.374595Z","iopub.status.idle":"2024-02-08T05:42:23.411859Z","shell.execute_reply.started":"2024-02-08T05:42:23.374558Z","shell.execute_reply":"2024-02-08T05:42:23.410375Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"import json\n# Collecting the model architectures according to the tasks\nwith open('task_arch.json', 'w') as mod:\n    json.dump(task_arch, mod)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:42:25.974173Z","iopub.execute_input":"2024-02-08T05:42:25.975091Z","iopub.status.idle":"2024-02-08T05:42:25.982386Z","shell.execute_reply.started":"2024-02-08T05:42:25.975047Z","shell.execute_reply":"2024-02-08T05:42:25.980823Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"### Seq2Seq Classification","metadata":{}},{"cell_type":"code","source":"distilbert_cls_path = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(distilbert_cls_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T03:44:19.902380Z","iopub.execute_input":"2024-02-08T03:44:19.903024Z","iopub.status.idle":"2024-02-08T03:44:20.133582Z","shell.execute_reply.started":"2024-02-08T03:44:19.902987Z","shell.execute_reply":"2024-02-08T03:44:20.132218Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"distilbert_model = AutoModelForSequenceClassification.from_pretrained(distilbert_cls_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T03:44:59.828279Z","iopub.execute_input":"2024-02-08T03:44:59.828808Z","iopub.status.idle":"2024-02-08T03:45:04.587487Z","shell.execute_reply.started":"2024-02-08T03:44:59.828770Z","shell.execute_reply":"2024-02-08T03:45:04.586555Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dbe08f1428f4ef494fb57a0cbc9443e"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"classify_text = \"This is a very nice way of getting things done\"\ntext_tokened = tokenizer(classify_text, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T03:57:09.978407Z","iopub.execute_input":"2024-02-08T03:57:09.978834Z","iopub.status.idle":"2024-02-08T03:57:09.985909Z","shell.execute_reply.started":"2024-02-08T03:57:09.978800Z","shell.execute_reply":"2024-02-08T03:57:09.984600Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"id2Label = {0:'negative', 1:'positive'}\nlabel2id = {'negative':0, 'positive':0}","metadata":{"execution":{"iopub.status.busy":"2024-02-08T03:50:25.630722Z","iopub.execute_input":"2024-02-08T03:50:25.632020Z","iopub.status.idle":"2024-02-08T03:50:25.637543Z","shell.execute_reply.started":"2024-02-08T03:50:25.631973Z","shell.execute_reply":"2024-02-08T03:50:25.636208Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"classification_logits = distilbert_model(**text_tokened).logits\npredicted_class_id = classification_logits.argmax().item()\nid2Label[predicted_class_id]","metadata":{"execution":{"iopub.status.busy":"2024-02-08T03:57:34.367685Z","iopub.execute_input":"2024-02-08T03:57:34.368127Z","iopub.status.idle":"2024-02-08T03:57:34.432368Z","shell.execute_reply.started":"2024-02-08T03:57:34.368096Z","shell.execute_reply":"2024-02-08T03:57:34.431093Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'negative'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Token Classification","metadata":{}},{"cell_type":"code","source":"# token classification labels are part of the datasets\nfrom datasets import load_dataset\nwnut = load_dataset('wnut_17')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:03:42.523308Z","iopub.execute_input":"2024-02-08T04:03:42.523824Z","iopub.status.idle":"2024-02-08T04:03:46.840463Z","shell.execute_reply.started":"2024-02-08T04:03:42.523791Z","shell.execute_reply":"2024-02-08T04:03:46.839049Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9c4957c31c40efbff06a092926cf90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d3450b3eb94702bdba979a2ff43be8"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset wnut_17/wnut_17 (download: 782.18 KiB, generated: 1.66 MiB, post-processed: Unknown size, total: 2.43 MiB) to /root/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3003f650ae9343e5927d8b7af9b99cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6783d3a8a8ed4fa8aceebb9e14db4d1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c46b33ab10c42068626341e80f970a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/66.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954b0c9c35484b47ac05993a3496e53b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba631123058642c29e0deb26c27b96ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset wnut_17 downloaded and prepared to /root/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c6d4c6a24e455fa44c0366db8b286b"}},"metadata":{}}]},{"cell_type":"code","source":"label_list = wnut['train'].features['ner_tags'].feature.names\nlabel_list","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:04:30.133035Z","iopub.execute_input":"2024-02-08T04:04:30.134212Z","iopub.status.idle":"2024-02-08T04:04:30.144496Z","shell.execute_reply.started":"2024-02-08T04:04:30.134160Z","shell.execute_reply":"2024-02-08T04:04:30.143023Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['O',\n 'B-corporation',\n 'I-corporation',\n 'B-creative-work',\n 'I-creative-work',\n 'B-group',\n 'I-group',\n 'B-location',\n 'I-location',\n 'B-person',\n 'I-person',\n 'B-product',\n 'I-product']"},"metadata":{}}]},{"cell_type":"code","source":"distilbert_tokencls_path = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(distilbert_tokencls_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:05:11.077455Z","iopub.execute_input":"2024-02-08T04:05:11.077916Z","iopub.status.idle":"2024-02-08T04:05:11.298467Z","shell.execute_reply.started":"2024-02-08T04:05:11.077884Z","shell.execute_reply":"2024-02-08T04:05:11.297206Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"wnut['train'][0]['tokens']","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:06:34.173048Z","iopub.execute_input":"2024-02-08T04:06:34.174145Z","iopub.status.idle":"2024-02-08T04:06:34.184294Z","shell.execute_reply.started":"2024-02-08T04:06:34.174086Z","shell.execute_reply":"2024-02-08T04:06:34.182841Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['@paulwalk',\n 'It',\n \"'s\",\n 'the',\n 'view',\n 'from',\n 'where',\n 'I',\n \"'m\",\n 'living',\n 'for',\n 'two',\n 'weeks',\n '.',\n 'Empire',\n 'State',\n 'Building',\n '=',\n 'ESB',\n '.',\n 'Pretty',\n 'bad',\n 'storm',\n 'here',\n 'last',\n 'evening',\n '.']"},"metadata":{}}]},{"cell_type":"code","source":"example = wnut['train'][0]\ntokened_input = tokenizer(example['tokens'], is_split_into_words=True)\ntokens = tokenizer.convert_ids_to_tokens(tokened_input['input_ids'])\ntokens  # additional tokens added in beginning, and at end","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:07:52.293705Z","iopub.execute_input":"2024-02-08T04:07:52.294213Z","iopub.status.idle":"2024-02-08T04:07:52.305229Z","shell.execute_reply.started":"2024-02-08T04:07:52.294179Z","shell.execute_reply":"2024-02-08T04:07:52.303758Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n '@',\n 'paul',\n '##walk',\n 'it',\n \"'\",\n 's',\n 'the',\n 'view',\n 'from',\n 'where',\n 'i',\n \"'\",\n 'm',\n 'living',\n 'for',\n 'two',\n 'weeks',\n '.',\n 'empire',\n 'state',\n 'building',\n '=',\n 'es',\n '##b',\n '.',\n 'pretty',\n 'bad',\n 'storm',\n 'here',\n 'last',\n 'evening',\n '.',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"id2label = {\n    0: \"O\",\n    1: \"B-corporation\",\n    2: \"I-corporation\",\n    3: \"B-creative-work\",\n    4: \"I-creative-work\",\n    5: \"B-group\",\n    6: \"I-group\",\n    7: \"B-location\",\n    8: \"I-location\",\n    9: \"B-person\",\n    10: \"I-person\",\n    11: \"B-product\",\n    12: \"I-product\",\n}\nlabel2id = {\n    \"O\": 0,\n    \"B-corporation\": 1,\n    \"I-corporation\": 2,\n    \"B-creative-work\": 3,\n    \"I-creative-work\": 4,\n    \"B-group\": 5,\n    \"I-group\": 6,\n    \"B-location\": 7,\n    \"I-location\": 8,\n    \"B-person\": 9,\n    \"I-person\": 10,\n    \"B-product\": 11,\n    \"I-product\": 12,\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:10:39.993610Z","iopub.execute_input":"2024-02-08T04:10:39.994172Z","iopub.status.idle":"2024-02-08T04:10:40.004156Z","shell.execute_reply.started":"2024-02-08T04:10:39.994112Z","shell.execute_reply":"2024-02-08T04:10:40.002442Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokened_input.word_ids(batch_index=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:09:59.683369Z","iopub.execute_input":"2024-02-08T04:09:59.684046Z","iopub.status.idle":"2024-02-08T04:09:59.695280Z","shell.execute_reply.started":"2024-02-08T04:09:59.684000Z","shell.execute_reply":"2024-02-08T04:09:59.693537Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[None,\n 0,\n 0,\n 0,\n 1,\n 2,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n None]"},"metadata":{}}]},{"cell_type":"code","source":"text = \"The Golden State Warriors are an American professional basketball team based in San Francisco.\"","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:11:35.633545Z","iopub.execute_input":"2024-02-08T04:11:35.634074Z","iopub.status.idle":"2024-02-08T04:11:35.641499Z","shell.execute_reply.started":"2024-02-08T04:11:35.634040Z","shell.execute_reply":"2024-02-08T04:11:35.639689Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(text, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:16:16.517462Z","iopub.execute_input":"2024-02-08T04:16:16.517986Z","iopub.status.idle":"2024-02-08T04:16:16.525527Z","shell.execute_reply.started":"2024-02-08T04:16:16.517952Z","shell.execute_reply":"2024-02-08T04:16:16.523933Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\ntokencls_model = AutoModelForTokenClassification.from_pretrained(distilbert_tokencls_path)\n\nwith torch.no_grad():\n    logits = tokencls_model(**inputs).logits","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:18:24.008276Z","iopub.execute_input":"2024-02-08T04:18:24.009686Z","iopub.status.idle":"2024-02-08T04:18:24.324454Z","shell.execute_reply.started":"2024-02-08T04:18:24.009632Z","shell.execute_reply":"2024-02-08T04:18:24.323211Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = torch.argmax(logits, dim=2)\npredicted_token_class = [id2label[t.item()] for t in predictions[0]]\npredicted_token_class","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:18:37.006447Z","iopub.execute_input":"2024-02-08T04:18:37.006919Z","iopub.status.idle":"2024-02-08T04:18:37.016087Z","shell.execute_reply.started":"2024-02-08T04:18:37.006883Z","shell.execute_reply":"2024-02-08T04:18:37.015279Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['O',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'O',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation',\n 'B-corporation']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Question Answering","metadata":{}},{"cell_type":"code","source":"distilbert_qa_path = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(distilbert_qa_path)\nqa_model = AutoModelForQuestionAnswering.from_pretrained(distilbert_qa_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:23:02.316876Z","iopub.execute_input":"2024-02-08T04:23:02.317399Z","iopub.status.idle":"2024-02-08T04:23:02.846732Z","shell.execute_reply.started":"2024-02-08T04:23:02.317362Z","shell.execute_reply":"2024-02-08T04:23:02.845218Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"question = \"How many programming languages does BLOOM support?\"\ncontext = \"\"\"BLOOM has 176 billion parameters and can \ngenerate text in 46 languages natural languages and 13 programming languages.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:23:44.127252Z","iopub.execute_input":"2024-02-08T04:23:44.128205Z","iopub.status.idle":"2024-02-08T04:23:44.137632Z","shell.execute_reply.started":"2024-02-08T04:23:44.128163Z","shell.execute_reply":"2024-02-08T04:23:44.136190Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(question, context, return_tensors='pt')  \n# question , context are a single tensor after tokenisation ","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:24:18.956388Z","iopub.execute_input":"2024-02-08T04:24:18.956875Z","iopub.status.idle":"2024-02-08T04:24:18.963962Z","shell.execute_reply.started":"2024-02-08T04:24:18.956840Z","shell.execute_reply":"2024-02-08T04:24:18.962952Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = qa_model(**inputs) ","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:26:54.292064Z","iopub.execute_input":"2024-02-08T04:26:54.292632Z","iopub.status.idle":"2024-02-08T04:26:54.354426Z","shell.execute_reply.started":"2024-02-08T04:26:54.292594Z","shell.execute_reply":"2024-02-08T04:26:54.353366Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"answer_start_index = outputs.start_logits.argmax()\nanswer_end_index = outputs.end_logits.argmax()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:27:08.272256Z","iopub.execute_input":"2024-02-08T04:27:08.272992Z","iopub.status.idle":"2024-02-08T04:27:08.278452Z","shell.execute_reply.started":"2024-02-08T04:27:08.272956Z","shell.execute_reply":"2024-02-08T04:27:08.277344Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"inputs.input_ids[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:32:01.852416Z","iopub.execute_input":"2024-02-08T04:32:01.852893Z","iopub.status.idle":"2024-02-08T04:32:01.861900Z","shell.execute_reply.started":"2024-02-08T04:32:01.852858Z","shell.execute_reply":"2024-02-08T04:32:01.860677Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor([[  101,  2129,  2116,  4730,  4155,  2515, 13426,  2490,  1029,   102,\n         13426,  2038, 18561,  4551, 11709,  1998,  2064,  9699,  3793,  1999,\n          4805,  4155,  3019,  4155,  1998,  2410,  4730,  4155,  1012,   102]])"},"metadata":{}}]},{"cell_type":"code","source":"predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\ntokenizer.decode(predict_answer_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T04:33:15.505859Z","iopub.execute_input":"2024-02-08T04:33:15.506426Z","iopub.status.idle":"2024-02-08T04:33:15.515853Z","shell.execute_reply.started":"2024-02-08T04:33:15.506389Z","shell.execute_reply":"2024-02-08T04:33:15.515030Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"''"},"metadata":{}}]},{"cell_type":"markdown","source":"### Causal Language Modeling","metadata":{}},{"cell_type":"code","source":"# Text Generation >> Uses the generate followed by tokenizer.decode\n\n# model_tg = 'gpt2'\nmodel_tg = 'distilgpt2'\n\nmodel_tokenizer = AutoTokenizer.from_pretrained(model_tg)\ncausal_gpt = AutoModelForCausalLM.from_pretrained(model_tg)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:10:07.391215Z","iopub.execute_input":"2024-02-08T05:10:07.392013Z","iopub.status.idle":"2024-02-08T05:10:12.625237Z","shell.execute_reply.started":"2024-02-08T05:10:07.391975Z","shell.execute_reply":"2024-02-08T05:10:12.623684Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5051bb34ea5438d9814dc06db7d7806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178e49c03b32441a9d502f9f3a201a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb23dc108dee41c7a758272e5fafd7fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4787b64afbc843ab92ec47f1741a0f5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a543a2f2ff5543aabcb4ced03ef7646b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f66367d8db842c7b1ee4154b8af33e2"}},"metadata":{}}]},{"cell_type":"code","source":"# model_tokenizer.add_special_tokens({'pad_token': '[PAD]'}) \n# can't do this, as it will raise when decoding the model output\nprint(model_tokenizer.pad_token_id)\nprint(model_tokenizer.eos_token_id)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:11:12.636260Z","iopub.execute_input":"2024-02-08T05:11:12.636743Z","iopub.status.idle":"2024-02-08T05:11:12.644636Z","shell.execute_reply.started":"2024-02-08T05:11:12.636711Z","shell.execute_reply":"2024-02-08T05:11:12.642956Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"None\n50256\n","output_type":"stream"}]},{"cell_type":"code","source":"model_tokenizer.pad_token_id = model_tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:11:18.021131Z","iopub.execute_input":"2024-02-08T05:11:18.021568Z","iopub.status.idle":"2024-02-08T05:11:18.026855Z","shell.execute_reply.started":"2024-02-08T05:11:18.021538Z","shell.execute_reply":"2024-02-08T05:11:18.025634Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"sentence = \"This is a seed sentence for enormous experiments that will be successful\"\n# tokened = model_tokenizer(sentence, padding='max_length', max_length=20, return_tensors='pt')\ntokened = model_tokenizer(sentence, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:11:47.820953Z","iopub.execute_input":"2024-02-08T05:11:47.821382Z","iopub.status.idle":"2024-02-08T05:11:47.831265Z","shell.execute_reply.started":"2024-02-08T05:11:47.821352Z","shell.execute_reply":"2024-02-08T05:11:47.829780Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"tokened","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:18:15.696796Z","iopub.execute_input":"2024-02-08T05:18:15.697360Z","iopub.status.idle":"2024-02-08T05:18:15.708450Z","shell.execute_reply.started":"2024-02-08T05:18:15.697327Z","shell.execute_reply":"2024-02-08T05:18:15.706781Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 1212,   318,   257,  9403,  6827,   329,  9812, 10256,   326,   481,\n           307,  4388]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}]},{"cell_type":"code","source":"causal_gpt.can_generate()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:11:53.410843Z","iopub.execute_input":"2024-02-08T05:11:53.411471Z","iopub.status.idle":"2024-02-08T05:11:53.420681Z","shell.execute_reply.started":"2024-02-08T05:11:53.411427Z","shell.execute_reply":"2024-02-08T05:11:53.419003Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"model_logits = causal_gpt.generate(tokened['input_ids'],\n                                  max_new_tokens=100, do_sample=True,\n                                  top_p=0.95)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:18:51.686784Z","iopub.execute_input":"2024-02-08T05:18:51.687279Z","iopub.status.idle":"2024-02-08T05:18:55.096026Z","shell.execute_reply.started":"2024-02-08T05:18:51.687247Z","shell.execute_reply":"2024-02-08T05:18:55.095120Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"# text generation output decoded \ntext_output = model_tokenizer.decode(model_logits[0], skip_special_tokens=True)\ntext_output","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:18:58.731250Z","iopub.execute_input":"2024-02-08T05:18:58.732069Z","iopub.status.idle":"2024-02-08T05:18:58.741597Z","shell.execute_reply.started":"2024-02-08T05:18:58.732003Z","shell.execute_reply":"2024-02-08T05:18:58.740157Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'This is a seed sentence for enormous experiments that will be successful in a short time, which will allow us to test the impact that the experiment would have on the human genome, which is much faster than in a biological experiment.\\n\\n\\n\\nWe think that for the first time it will be a new way to learn about the impact of genes that are involved in a human genome.\\nWe think that the next evolution will be the ability for other human cells to reproduce into other cells on the same size as our own.\\nWe have seen how people use'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Masked Language Modeling","metadata":{}},{"cell_type":"code","source":"model_masked_path = \"distilroberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_masked_path)\nmodel_masked = AutoModelForMaskedLM.from_pretrained(model_masked_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:21:59.201043Z","iopub.execute_input":"2024-02-08T05:21:59.201527Z","iopub.status.idle":"2024-02-08T05:22:03.740302Z","shell.execute_reply.started":"2024-02-08T05:21:59.201493Z","shell.execute_reply":"2024-02-08T05:22:03.739221Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98fca9b524a94b7baae0e2ac928f70f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443f186bc94e41b38b4725a0c9e089c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defc46593e0f4ef79ac5e1396ff8c008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be37e84378884ab79d3ce61d0abec6bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e057c9109bde425d82bc57a342aefbbf"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"The Milky Way is a <mask> galaxy.\"\ninputs = tokenizer(text, return_tensors='pt')\nmask_token_index = torch.where(inputs['input_ids'] == tokenizer.mask_token_id)[1]","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:23:49.781413Z","iopub.execute_input":"2024-02-08T05:23:49.782217Z","iopub.status.idle":"2024-02-08T05:23:49.793850Z","shell.execute_reply.started":"2024-02-08T05:23:49.782181Z","shell.execute_reply":"2024-02-08T05:23:49.792482Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"logits = model_masked(**inputs).logits\nmask_token_logits = logits[0, mask_token_index, :]","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:27:46.896076Z","iopub.execute_input":"2024-02-08T05:27:46.896638Z","iopub.status.idle":"2024-02-08T05:27:46.965869Z","shell.execute_reply.started":"2024-02-08T05:27:46.896603Z","shell.execute_reply":"2024-02-08T05:27:46.964424Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"mask_token_logits","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:27:56.605925Z","iopub.execute_input":"2024-02-08T05:27:56.606921Z","iopub.status.idle":"2024-02-08T05:27:56.623918Z","shell.execute_reply.started":"2024-02-08T05:27:56.606880Z","shell.execute_reply":"2024-02-08T05:27:56.622949Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"tensor([[-2.0420, -3.1702,  3.7433,  ..., -1.2430, -2.4243,  1.4616]],\n       grad_fn=<IndexBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices[0].tolist()\nfor tokens in top_3_tokens:\n    print(text.replace(tokenizer.mask_token, tokenizer.decode([tokens])))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:29:45.036825Z","iopub.execute_input":"2024-02-08T05:29:45.037579Z","iopub.status.idle":"2024-02-08T05:29:58.558393Z","shell.execute_reply.started":"2024-02-08T05:29:45.037544Z","shell.execute_reply":"2024-02-08T05:29:58.556756Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"2024-02-08 05:29:47.016871: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-08 05:29:47.017017: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-08 05:29:47.162271: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"The Milky Way is a  spiral galaxy.\nThe Milky Way is a  dwarf galaxy.\nThe Milky Way is a  massive galaxy.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Translation","metadata":{}},{"cell_type":"code","source":"model_translation_path = 't5-small'\ntokenizer = AutoTokenizer.from_pretrained(model_translation_path)\nmodel_translation = AutoModelForSeq2SeqLM.from_pretrained(model_translation_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:35:23.226652Z","iopub.execute_input":"2024-02-08T05:35:23.227161Z","iopub.status.idle":"2024-02-08T05:35:26.643546Z","shell.execute_reply.started":"2024-02-08T05:35:23.227112Z","shell.execute_reply":"2024-02-08T05:35:26.642057Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55815be0621b4b77ab526933bf572803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1143982117449c940d1ddaf674ee12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9431e6a71c5046f6b1a32d61f458558e"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\"","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:35:44.651027Z","iopub.execute_input":"2024-02-08T05:35:44.651507Z","iopub.status.idle":"2024-02-08T05:35:44.658620Z","shell.execute_reply.started":"2024-02-08T05:35:44.651473Z","shell.execute_reply":"2024-02-08T05:35:44.656994Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(text, return_tensors=\"pt\").input_ids\noutputs = model_translation.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:36:47.265814Z","iopub.execute_input":"2024-02-08T05:36:47.266360Z","iopub.status.idle":"2024-02-08T05:36:47.940574Z","shell.execute_reply.started":"2024-02-08T05:36:47.266322Z","shell.execute_reply":"2024-02-08T05:36:47.939509Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:36:55.471188Z","iopub.execute_input":"2024-02-08T05:36:55.471676Z","iopub.status.idle":"2024-02-08T05:36:55.480340Z","shell.execute_reply.started":"2024-02-08T05:36:55.471640Z","shell.execute_reply":"2024-02-08T05:36:55.479004Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"\"Les lègumes partagent les ressources avec les bactéries fixant l'azote.\""},"metadata":{}}]},{"cell_type":"markdown","source":"### Summarisation","metadata":{}},{"cell_type":"code","source":"model_summarisation_path = 't5-small'\ntokenizer = AutoTokenizer.from_pretrained(model_summarisation_path)\nmodel_summarisation = AutoModelForSeq2SeqLM.from_pretrained(model_summarisation_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:40:19.836002Z","iopub.execute_input":"2024-02-08T05:40:19.837404Z","iopub.status.idle":"2024-02-08T05:40:20.803789Z","shell.execute_reply.started":"2024-02-08T05:40:19.837353Z","shell.execute_reply":"2024-02-08T05:40:20.802396Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\"","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:40:32.504858Z","iopub.execute_input":"2024-02-08T05:40:32.505996Z","iopub.status.idle":"2024-02-08T05:40:32.510540Z","shell.execute_reply.started":"2024-02-08T05:40:32.505956Z","shell.execute_reply":"2024-02-08T05:40:32.509723Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(text, return_tensors=\"pt\").input_ids","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:40:47.969599Z","iopub.execute_input":"2024-02-08T05:40:47.970081Z","iopub.status.idle":"2024-02-08T05:40:47.976444Z","shell.execute_reply.started":"2024-02-08T05:40:47.970047Z","shell.execute_reply":"2024-02-08T05:40:47.975330Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"outputs = model_summarisation.generate(inputs, max_new_tokens=100, do_sample=False)\ntokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:41:13.609890Z","iopub.execute_input":"2024-02-08T05:41:13.610373Z","iopub.status.idle":"2024-02-08T05:41:14.921458Z","shell.execute_reply.started":"2024-02-08T05:41:13.610338Z","shell.execute_reply":"2024-02-08T05:41:14.920222Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"\"the inflation reduction act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in american history. it will ask the ultra-wealthy and corporations to pay their fair share.\""},"metadata":{}}]},{"cell_type":"markdown","source":"### Multiple Choice ","metadata":{}},{"cell_type":"code","source":"model_multi_path = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_multi_path)\nmodel_multi = AutoModelForMultipleChoice.from_pretrained(model_multi_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:46:40.382066Z","iopub.execute_input":"2024-02-08T05:46:40.383276Z","iopub.status.idle":"2024-02-08T05:46:44.520804Z","shell.execute_reply.started":"2024-02-08T05:46:40.383231Z","shell.execute_reply":"2024-02-08T05:46:44.519604Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6af0de6da1f44a5bfce99708a7c004a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b80ea42bc084f9b84cfa5a82dfae698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf6f7914b7f7475f8c8c030bb7c20778"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3740b4bab9e4f75957127c847f59ffe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e408b21693fa4dd0a86c7c3c2da415d5"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = \"France has a bread law, Le Décret Pain, with strict rules on what is allowed in a traditional baguette.\"\ncandidate1 = \"The law does not apply to croissants and brioche.\"\ncandidate2 = \"The law applies to baguettes.\"","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:46:51.346724Z","iopub.execute_input":"2024-02-08T05:46:51.347224Z","iopub.status.idle":"2024-02-08T05:46:51.354010Z","shell.execute_reply.started":"2024-02-08T05:46:51.347185Z","shell.execute_reply":"2024-02-08T05:46:51.352385Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer([[prompt, candidate1],\n                    [prompt, candidate2]], \n                   return_tensors=\"pt\", padding=True)\n\nlabels = torch.tensor(0).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:47:16.481431Z","iopub.execute_input":"2024-02-08T05:47:16.481952Z","iopub.status.idle":"2024-02-08T05:47:16.490008Z","shell.execute_reply.started":"2024-02-08T05:47:16.481917Z","shell.execute_reply":"2024-02-08T05:47:16.488699Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"outputs = model_multi(**{k: v.unsqueeze(0) for k, v in inputs.items()},\n                      labels=labels)\nlogits = outputs.logits\npredicted_class = logits.argmax().item()\npredicted_class","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:47:52.111482Z","iopub.execute_input":"2024-02-08T05:47:52.111974Z","iopub.status.idle":"2024-02-08T05:47:52.339020Z","shell.execute_reply.started":"2024-02-08T05:47:52.111943Z","shell.execute_reply":"2024-02-08T05:47:52.338170Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]}]}