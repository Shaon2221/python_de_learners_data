{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# In this a custom DataCollator DataClass is written for managing\n# the multiple choice training","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"bert-base-uncased\"\nbatch_size = 16","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-02T12:20:01.904272Z","iopub.execute_input":"2024-02-02T12:20:01.904666Z","iopub.status.idle":"2024-02-02T12:20:01.938126Z","shell.execute_reply.started":"2024-02-02T12:20:01.904634Z","shell.execute_reply":"2024-02-02T12:20:01.936332Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:20:14.364155Z","iopub.execute_input":"2024-02-02T12:20:14.365150Z","iopub.status.idle":"2024-02-02T12:20:16.538504Z","shell.execute_reply.started":"2024-02-02T12:20:14.365104Z","shell.execute_reply":"2024-02-02T12:20:16.537365Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"datasets = load_dataset(\"swag\", \"regular\")","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:20:21.742518Z","iopub.execute_input":"2024-02-02T12:20:21.743177Z","iopub.status.idle":"2024-02-02T12:20:43.378535Z","shell.execute_reply.started":"2024-02-02T12:20:21.743141Z","shell.execute_reply":"2024-02-02T12:20:43.377412Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9e7828175f04e08a8ca9bd66bf95d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d7371c66794c26ad0d40daca4d3cfd"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset swag/regular (download: 41.92 MiB, generated: 44.96 MiB, post-processed: Unknown size, total: 86.88 MiB) to /root/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45316e0c6826415a8a4fa8ba8f2252e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b0818933a44ef3a9e1e3fd58536b60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1979fb5c35c4074af538f5ae15303da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.21M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d63218de83994b2a8d309371002ea903"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0b84e5d3d445d997f573055097baf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/73546 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/20006 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/20005 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset swag downloaded and prepared to /root/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a8e4c1c1db647ba918cc806a7bdf9ae"}},"metadata":{}}]},{"cell_type":"code","source":"datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:20:49.042708Z","iopub.execute_input":"2024-02-02T12:20:49.043119Z","iopub.status.idle":"2024-02-02T12:20:49.050729Z","shell.execute_reply.started":"2024-02-02T12:20:49.043088Z","shell.execute_reply":"2024-02-02T12:20:49.049457Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n        num_rows: 73546\n    })\n    validation: Dataset({\n        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n        num_rows: 20006\n    })\n    test: Dataset({\n        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n        num_rows: 20005\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"datasets['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:21:05.187215Z","iopub.execute_input":"2024-02-02T12:21:05.187615Z","iopub.status.idle":"2024-02-02T12:21:05.203084Z","shell.execute_reply.started":"2024-02-02T12:21:05.187587Z","shell.execute_reply":"2024-02-02T12:21:05.201799Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'video-id': 'anetv_jkn6uvmqwh4',\n 'fold-ind': '3416',\n 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n 'sent2': 'A drum line',\n 'gold-source': 'gold',\n 'ending0': 'passes by walking down the street playing their instruments.',\n 'ending1': 'has heard approaching them.',\n 'ending2': \"arrives and they're outside dancing and asleep.\",\n 'ending3': 'turns the lead singer watches the performance.',\n 'label': 0}"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n    display(HTML(df.to_html()))","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:21:40.528833Z","iopub.execute_input":"2024-02-02T12:21:40.529255Z","iopub.status.idle":"2024-02-02T12:21:40.538625Z","shell.execute_reply.started":"2024-02-02T12:21:40.529224Z","shell.execute_reply":"2024-02-02T12:21:40.537464Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"show_random_elements(datasets['train'],2)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:21:54.094353Z","iopub.execute_input":"2024-02-02T12:21:54.094800Z","iopub.status.idle":"2024-02-02T12:21:54.116146Z","shell.execute_reply.started":"2024-02-02T12:21:54.094767Z","shell.execute_reply":"2024-02-02T12:21:54.115249Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video-id</th>\n      <th>fold-ind</th>\n      <th>startphrase</th>\n      <th>sent1</th>\n      <th>sent2</th>\n      <th>gold-source</th>\n      <th>ending0</th>\n      <th>ending1</th>\n      <th>ending2</th>\n      <th>ending3</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>anetv_eyBSKNXo6Vo</td>\n      <td>13566</td>\n      <td>A pro skier instructs young children on how to water ski. Clips of a young boy and young girl</td>\n      <td>A pro skier instructs young children on how to water ski.</td>\n      <td>Clips of a young boy and young girl</td>\n      <td>gold</td>\n      <td>jump over down the hill holding the hands up.</td>\n      <td>playing in the shallow water.</td>\n      <td>are shown involved in a video tournament.</td>\n      <td>are standing on a roof of a jet.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anetv_OT98MiVje0g</td>\n      <td>13286</td>\n      <td>A close up is seen of Christmas decorations. A man in Santa Claus costume</td>\n      <td>A close up is seen of Christmas decorations.</td>\n      <td>A man in Santa Claus costume</td>\n      <td>gen</td>\n      <td>walks up on the tops of the tree.</td>\n      <td>is holding more dust off onto the ground watching.</td>\n      <td>speaks to the camera and cuts up a pumpkin.</td>\n      <td>holds an orange green castle christmas garland.</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"def show_one(example):\n    print(f\"Context: {example['sent1']}\")\n    print(f\"  A - {example['sent2']} {example['ending0']}\")\n    print(f\"  B - {example['sent2']} {example['ending1']}\")\n    print(f\"  C - {example['sent2']} {example['ending2']}\")\n    print(f\"  D - {example['sent2']} {example['ending3']}\")\n    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:22:18.816624Z","iopub.execute_input":"2024-02-02T12:22:18.817087Z","iopub.status.idle":"2024-02-02T12:22:18.823806Z","shell.execute_reply.started":"2024-02-02T12:22:18.817045Z","shell.execute_reply":"2024-02-02T12:22:18.822434Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"show_one(datasets['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:22:44.185076Z","iopub.execute_input":"2024-02-02T12:22:44.185463Z","iopub.status.idle":"2024-02-02T12:22:44.191855Z","shell.execute_reply.started":"2024-02-02T12:22:44.185436Z","shell.execute_reply":"2024-02-02T12:22:44.190792Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Context: Members of the procession walk down the street holding small horn brass instruments.\n  A - A drum line passes by walking down the street playing their instruments.\n  B - A drum line has heard approaching them.\n  C - A drum line arrives and they're outside dancing and asleep.\n  D - A drum line turns the lead singer watches the performance.\n\nGround truth: option A\n","output_type":"stream"}]},{"cell_type":"code","source":"show_one(datasets[\"train\"][15])","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:23:12.488459Z","iopub.execute_input":"2024-02-02T12:23:12.488853Z","iopub.status.idle":"2024-02-02T12:23:12.495246Z","shell.execute_reply.started":"2024-02-02T12:23:12.488825Z","shell.execute_reply":"2024-02-02T12:23:12.494159Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Context: Now it's someone's turn to rain blades on his opponent.\n  A - Someone pats his shoulder and spins wildly.\n  B - Someone lunges forward through the window.\n  C - Someone falls to the ground.\n  D - Someone rolls up his fast run from the water and tosses in the sky.\n\nGround truth: option C\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint,\n                                          use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:23:36.083226Z","iopub.execute_input":"2024-02-02T12:23:36.083637Z","iopub.status.idle":"2024-02-02T12:23:42.301490Z","shell.execute_reply.started":"2024-02-02T12:23:36.083607Z","shell.execute_reply":"2024-02-02T12:23:42.300483Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1729b82e77344a90a07f4b769f327933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a682ac096424501bd2f16468f1af39f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da0b16ca646407aa2e607b2a9db4018"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7cd9f8cf3b74b27a3dc566a56ec4dcf"}},"metadata":{}}]},{"cell_type":"code","source":"ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\nfrom typing import List\n\ndef preprocess_function(examples: List):\n    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n    # Grab all second sentences possible for each context.\n    # print(first_sentences)\n    question_headers = examples[\"sent2\"]\n    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n    # print(second_sentences)\n    # Flatten everything\n    first_sentences = sum(first_sentences, [])\n    \n    second_sentences = sum(second_sentences, [])\n    \n    # Tokenize\n    tokenized_examples = tokenizer(first_sentences,\n                                   second_sentences,\n                                   truncation=True)\n    # Un-flatten\n    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:31:38.563891Z","iopub.execute_input":"2024-02-02T12:31:38.564446Z","iopub.status.idle":"2024-02-02T12:31:38.574175Z","shell.execute_reply.started":"2024-02-02T12:31:38.564410Z","shell.execute_reply":"2024-02-02T12:31:38.572784Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"features = preprocess_function(datasets['train'][:2])\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:32:17.505211Z","iopub.execute_input":"2024-02-02T12:32:17.505669Z","iopub.status.idle":"2024-02-02T12:32:17.513955Z","shell.execute_reply.started":"2024-02-02T12:32:17.505637Z","shell.execute_reply":"2024-02-02T12:32:17.512880Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'input_ids': [[[101, 2372, 1997, 1996, 14385, 3328, 2091, 1996, 2395, 3173, 2235, 7109, 8782, 5693, 1012, 102, 1037, 6943, 2240, 5235, 2011, 3788, 2091, 1996, 2395, 2652, 2037, 5693, 1012, 102], [101, 2372, 1997, 1996, 14385, 3328, 2091, 1996, 2395, 3173, 2235, 7109, 8782, 5693, 1012, 102, 1037, 6943, 2240, 2038, 2657, 8455, 2068, 1012, 102], [101, 2372, 1997, 1996, 14385, 3328, 2091, 1996, 2395, 3173, 2235, 7109, 8782, 5693, 1012, 102, 1037, 6943, 2240, 8480, 1998, 2027, 1005, 2128, 2648, 5613, 1998, 6680, 1012, 102], [101, 2372, 1997, 1996, 14385, 3328, 2091, 1996, 2395, 3173, 2235, 7109, 8782, 5693, 1012, 102, 1037, 6943, 2240, 4332, 1996, 2599, 3220, 12197, 1996, 2836, 1012, 102]], [[101, 1037, 6943, 2240, 5235, 2011, 3788, 2091, 1996, 2395, 2652, 2037, 5693, 1012, 102, 2372, 1997, 1996, 14385, 2024, 2652, 17852, 13433, 3070, 1998, 12964, 2028, 2187, 2169, 1999, 4248, 1012, 102], [101, 1037, 6943, 2240, 5235, 2011, 3788, 2091, 1996, 2395, 2652, 2037, 5693, 1012, 102, 2372, 1997, 1996, 14385, 3524, 3254, 2875, 1996, 15724, 1012, 102], [101, 1037, 6943, 2240, 5235, 2011, 3788, 2091, 1996, 2395, 2652, 2037, 5693, 1012, 102, 2372, 1997, 1996, 14385, 4247, 2000, 2377, 2004, 2092, 2247, 1996, 4306, 2247, 2007, 1996, 2316, 2108, 10263, 1012, 102], [101, 1037, 6943, 2240, 5235, 2011, 3788, 2091, 1996, 2395, 2652, 2037, 5693, 1012, 102, 2372, 1997, 1996, 14385, 3613, 2000, 2377, 10998, 1010, 25338, 1012, 102]]], 'token_type_ids': [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], 'attention_mask': [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]}\n","output_type":"stream"}]},{"cell_type":"code","source":"idx = 1\n[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(4)]","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:32:38.651514Z","iopub.execute_input":"2024-02-02T12:32:38.652178Z","iopub.status.idle":"2024-02-02T12:32:51.905792Z","shell.execute_reply.started":"2024-02-02T12:32:38.652148Z","shell.execute_reply":"2024-02-02T12:32:51.904661Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"2024-02-02 12:32:40.876795: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-02 12:32:40.877130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-02 12:32:41.039070: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession are playing ping pong and celebrating one left each in quick. [SEP]',\n '[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession wait slowly towards the cadets. [SEP]',\n '[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession continues to play as well along the crowd along with the band being interviewed. [SEP]',\n '[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession continue to play marching, interspersed. [SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"encoded_datasets = datasets.map(preprocess_function,\n                                batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:33:08.824652Z","iopub.execute_input":"2024-02-02T12:33:08.826202Z","iopub.status.idle":"2024-02-02T12:34:01.824904Z","shell.execute_reply.started":"2024-02-02T12:33:08.826160Z","shell.execute_reply":"2024-02-02T12:34:01.823845Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/74 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e855169eb5374d7abd8f426beef69c4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/21 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddc3aff48f3647b7a17bcdc8fc9803ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/21 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3b2e01148e5433989bc060c497abf28"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForMultipleChoice,\n    TrainingArguments,\n    Trainer\n)\n\nmodel = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:34:01.827290Z","iopub.execute_input":"2024-02-02T12:34:01.827690Z","iopub.status.idle":"2024-02-02T12:34:06.835497Z","shell.execute_reply.started":"2024-02-02T12:34:01.827661Z","shell.execute_reply":"2024-02-02T12:34:06.834484Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb1e70ecf704120812cfe9561680421"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = model_checkpoint.split(\"/\")[-1]\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-swag\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=False,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:34:12.106153Z","iopub.execute_input":"2024-02-02T12:34:12.106540Z","iopub.status.idle":"2024-02-02T12:34:12.116272Z","shell.execute_reply.started":"2024-02-02T12:34:12.106514Z","shell.execute_reply":"2024-02-02T12:34:12.115327Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Then we need to tell our Trainer how to form batches from the pre-processed inputs. We haven't done any padding yet because we will pad each batch to the maximum length inside the batch (instead of doing so with the maximum length of the whole dataset). This will be the job of the data collator. A data collator takes a list of examples and converts them to a batch (by, in our case, applying padding). Since there is no data collator in the library that works on our specific problem, we will write one, adapted from the DataCollatorWithPadding:","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom transformers.tokenization_utils_base import (\n    PreTrainedTokenizerBase, \n    PaddingStrategy\n)\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    \"\"\"\n    Data collator that will dynamically pad the inputs for multiple choice received.\n    \"\"\"\n\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n\n    def __call__(self, features):\n        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0][\"input_ids\"])\n        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        \n        # Un-flatten\n        batch = {k: v.view(batch_size, num_choices, -1) \\\n                 for k, v in batch.items()}\n        # Add back labels\n        batch[\"labels\"] = torch.tensor(labels,\n                                       dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:36:41.098015Z","iopub.execute_input":"2024-02-02T12:36:41.098924Z","iopub.status.idle":"2024-02-02T12:36:41.111475Z","shell.execute_reply.started":"2024-02-02T12:36:41.098889Z","shell.execute_reply":"2024-02-02T12:36:41.110442Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"When called on a list of examples, it will flatten all the inputs/attentions masks etc. in big lists that it will pass to the tokenizer.pad method. This will return a dictionary with big tensors (of shape (batch_size * 4) x seq_length) that we then unflatten.\n\nWe can check this data collator works on a list of features, we just have to make sure to remove all features that are not inputs accepted by our model (something the Trainer will do automatically for us after)","metadata":{}},{"cell_type":"code","source":"accepted_keys = [\"input_ids\",\n                 \"attention_mask\",\n                 \"label\"]\nfeatures = [{k: v for k, v in encoded_datasets[\"train\"][i].items() \\\n             if k in accepted_keys} for i in range(10)]\n\nbatch = DataCollatorForMultipleChoice(tokenizer)(features)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:36:45.945382Z","iopub.execute_input":"2024-02-02T12:36:45.945782Z","iopub.status.idle":"2024-02-02T12:36:45.963002Z","shell.execute_reply.started":"2024-02-02T12:36:45.945754Z","shell.execute_reply":"2024-02-02T12:36:45.962029Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(eval_predictions):\n    predictions, label_ids = eval_predictions\n    preds = np.argmax(predictions, axis=1)\n    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:37:20.340170Z","iopub.execute_input":"2024-02-02T12:37:20.340606Z","iopub.status.idle":"2024-02-02T12:37:20.347542Z","shell.execute_reply.started":"2024-02-02T12:37:20.340574Z","shell.execute_reply":"2024-02-02T12:37:20.346297Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_datasets[\"train\"],\n    eval_dataset=encoded_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer),\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T12:37:31.063421Z","iopub.execute_input":"2024-02-02T12:37:31.063876Z","iopub.status.idle":"2024-02-02T12:37:31.089428Z","shell.execute_reply.started":"2024-02-02T12:37:31.063843Z","shell.execute_reply":"2024-02-02T12:37:31.088388Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{},"execution_count":null,"outputs":[]}]}