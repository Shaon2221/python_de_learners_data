{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using wiki-text for causal and masked language modeling\n",
    "wiki_data = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue mrpc is used for peft model training\n",
    "glue_mrpc = load_dataset(\"glue\", 'mrpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue cola is used for text classification\n",
    "glue_cola = load_dataset(\"glue\", \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the datasets to local for easier loading & working\n",
    "# Got all the datasets locally\n",
    "glue_tasks = ['ax', 'cola', 'mnli', 'mnli_matched',\n",
    "              'mnli_mismatched', 'mrpc', 'qnli',\n",
    "              'qqp', 'rte', 'sst2', 'stsb', 'wnli']\n",
    "# glue all tasks download\n",
    "for task in glue_tasks[3:]:\n",
    "    print(task)\n",
    "    temp = load_dataset('glue', task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QnA training, got both the datasets\n",
    "squad_v1 = load_dataset(\"squad\", split='all')\n",
    "squad_v2 = load_dataset(\"squad_v2\", split='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Choice\n",
    "swag = load_dataset(\"swag\", 'regular') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER dataset\n",
    "conll = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openAssistant Mistral FT dataset\n",
    "oasst_top1 = load_dataset(\"OpenAssistant/oasst_top1_2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasst_1 = load_dataset(\"OpenAssistant/oasst1\")\n",
    "oasst_2 = load_dataset(\"OpenAssistant/oasst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter stances and classification \n",
    "twitter_list = [\"emoji\", \"emotion\", \"hate\", \"irony\", \n",
    "\"offensive\", \"sentiment\", \"stance_abortion\", \"stance_atheism\", \n",
    "\"stance_climate\", \"stance_feminist\", \"stance_hillary\"]\n",
    "\n",
    "for task in twitter_list:\n",
    "    twitter = load_dataset(\"tweet_eval\", task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used twitter_complaints in prompt_tuning\n",
    "ought_list = ['ade_corpus_v2', 'banking_77', 'terms_of_service', \n",
    "              'tai_safety_research', 'neurips_impact_statement_risks',\n",
    "              'overruling', 'systematic_review_inclusion', 'one_stop_english',\n",
    "              'tweet_eval_hate', 'twitter_complaints', 'semiconductor_org_types']\n",
    "for task in ought_list:\n",
    "    dataset = load_dataset(\"ought/raft\", task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@geronimo7/finetuning-llama2-mistral-945f9c200611\n",
    "# https://huggingface.co/teknium/OpenHermes-2-Mistral-7B\n",
    "open_orca = load_dataset(\"Open-Orca/OpenOrca\",)  # Need to re-download, 3.1GB data required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning on podcast\n",
    "dataset = load_dataset(\"g-ronimo/lfpodcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"g-ronimo/riddles_evolved\")\n",
    "# https://github.com/blancsw/deep_4_all/tree/main\n",
    "dataset = load_dataset(\"g-ronimo/oasst2_top1_en_answers-mistral\")\n",
    "dataset = load_dataset(\"g-ronimo/oasst2_top1_en_answers-mixtral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmsys_human_judge = load_dataset(\"lmsys/mt_bench_human_judgments\")\n",
    "lmsys_toxic_chat = load_dataset(\"lmsys/toxic-chat\", 'toxicchat0124')\n",
    "lmsys_toxic_chat = load_dataset(\"lmsys/toxic-chat\", 'toxicchat1123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6197b1929354a8cbf967ee3bc523ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "lmsys_1m = load_dataset(\"lmsys/lmsys-chat-1m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
