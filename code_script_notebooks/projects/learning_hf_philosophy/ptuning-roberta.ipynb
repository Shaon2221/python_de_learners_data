{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft evaluate >> /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-04T15:08:08.501449Z","iopub.execute_input":"2024-02-04T15:08:08.501863Z","iopub.status.idle":"2024-02-04T15:08:24.760643Z","shell.execute_reply.started":"2024-02-04T15:08:08.501833Z","shell.execute_reply":"2024-02-04T15:08:24.758904Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"This guide will show you how to train a roberta-large model (but you can also use any of the GPT, OPT, or BLOOM models) with p-tuning on the mrpc configuration of the GLUE benchmark","metadata":{}},{"cell_type":"code","source":"from transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer,\n)\nfrom peft import (\n    get_peft_config,\n    get_peft_model,\n    get_peft_model_state_dict,\n    set_peft_model_state_dict,\n    PeftType,\n    PromptEncoderConfig,\n)\nfrom datasets import load_dataset\nimport evaluate\nimport torch\n\nmodel_name_or_path = \"roberta-large\"\ntask = \"mrpc\"\n\nnum_epochs = 20\nlr = 1e-3\n\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-02-04T15:09:06.030617Z","iopub.execute_input":"2024-02-04T15:09:06.031232Z","iopub.status.idle":"2024-02-04T15:09:08.402243Z","shell.execute_reply.started":"2024-02-04T15:09:06.031171Z","shell.execute_reply":"2024-02-04T15:09:08.400947Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"glue\", task)\n\ndataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-04T15:07:20.108359Z","iopub.status.idle":"2024-02-04T15:07:20.109350Z","shell.execute_reply.started":"2024-02-04T15:07:20.109137Z","shell.execute_reply":"2024-02-04T15:07:20.109157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"glue\", task)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T15:09:21.796781Z","iopub.execute_input":"2024-02-04T15:09:21.797236Z","iopub.status.idle":"2024-02-04T15:09:22.558323Z","shell.execute_reply.started":"2024-02-04T15:09:21.797201Z","shell.execute_reply":"2024-02-04T15:09:22.556949Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f165cc5be740d9ad11c98d61b3d2b5"}},"metadata":{}}]},{"cell_type":"code","source":"Copied\nimport numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T15:07:20.113112Z","iopub.status.idle":"2024-02-04T15:07:20.113785Z","shell.execute_reply.started":"2024-02-04T15:07:20.113571Z","shell.execute_reply":"2024-02-04T15:07:20.113589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n    padding_side = \"left\"\nelse:\n    padding_side = \"right\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n\nif getattr(tokenizer, \"pad_token_id\") is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\n\n\ndef tokenize_function(examples):\n    # max_length=None => use the model max length (it's actually the default)\n    outputs = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=None)\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2024-02-04T15:07:20.115045Z","iopub.status.idle":"2024-02-04T15:07:20.115724Z","shell.execute_reply.started":"2024-02-04T15:07:20.115511Z","shell.execute_reply":"2024-02-04T15:07:20.115529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n)\n\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer,\n                                        padding=\"longest\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"P-tuning uses a prompt encoder to optimize the prompt parameters, so you’ll need to initialize the PromptEncoderConfig with several arguments:\n\n**task_type:** the type of task you’re training on, in this case it is sequence classification or SEQ_CLS\n\n**num_virtual_tokens:** the number of virtual tokens to use, or in other words, the prompt\n\n**encoder_hidden_size:** the hidden size of the encoder used to optimize the prompt parameters","metadata":{}},{"cell_type":"code","source":"peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\",\n                                  num_virtual_tokens=20,\n                                  encoder_hidden_size=128)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,\n                                                           return_dict=True)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"your-name/roberta-large-peft-p-tuning\",\n    learning_rate=1e-3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\npeft_model_id = \"smangrul/roberta-large-peft-p-tuning\"\nconfig = PeftConfig.from_pretrained(peft_model_id)\ninference_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\nmodel = PeftModel.from_pretrained(inference_model, peft_model_id","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = [\"not equivalent\", \"equivalent\"]\n\nsentence1 = \"Coast redwood trees are the tallest trees on the planet and can grow over 300 feet tall.\"\nsentence2 = \"The coast redwood trees, which can attain a height of over 300 feet, are the tallest trees on earth.\"\n\ninputs = tokenizer(sentence1, sentence2, truncation=True, padding=\"longest\", return_tensors=\"pt\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = model(**inputs).logits\n    print(outputs)\n\nparaphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\nfor i in range(len(classes)):\n    print(f\"{classes[i]}: {int(round(paraphrased_text[i] * 100))}%\")","metadata":{},"execution_count":null,"outputs":[]}]}