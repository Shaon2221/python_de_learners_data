{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Demonstrate-Search-Predict (DSP), with 'Py'thon\n",
    "\n",
    "- Developed by SNLPG team, show the list  \n",
    "\n",
    "- DSPy provides general purpose modules that replace string-based \n",
    "  prompting. DSPy also provides optimizers which can optimize these \n",
    "  modules with help of following\n",
    "\n",
    "- What are the various modules DSPy has?\n",
    "  Lang Models, Signatures, Modules, Data, Metrics, Optimizers, Assertions\n",
    "\n",
    "- Can you talk about use cases of DSPy?\n",
    "  QA, Classification, Summarisatio, RAGs / Multi-Hop rags, \n",
    "  Reasoning\n",
    "\n",
    "- Can we see a basic example of the DSPy code?\n",
    "    Has a LM, Signature, Module and execution. \n",
    "    Code follows below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Example of DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('D:\\\\gitFolders\\\\python_de_learners_data\\\\.env')\n",
    "import openai\n",
    "import os\n",
    "from dspy import (\n",
    "    Signature,\n",
    "    OpenAI,\n",
    "    Predict,\n",
    "    settings\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "# openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo  = OpenAI(model='gpt-3.5-turbo',)\n",
    "settings.configure(lm=turbo)\n",
    "# settings.configure(turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can access the LM directly as below\n",
    "turbo(\"Hi there, I am using DSPY...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way is to use the Modules \n",
    "pred_mod = Predict('question -> answer')\n",
    "model_out = pred_mod(question='WHere is Lunar landing happend the first time?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Question: Where is Lunar landing happened the first time?\\nAnswer: The first Lunar landing happened on the Moon.'\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is Lunar landing happened the first time?\n",
      "Answer: The first Lunar landing happened on the Moon.\n"
     ]
    }
   ],
   "source": [
    "print(model_out.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: WHere is Lunar landing happend the first time?\\nAnswer:',\n",
       "  'response': {'id': 'chatcmpl-8yvKkXsAN5lNoKIrXwpL5P9j23jd2',\n",
       "   'choices': [{'finish_reason': 'stop',\n",
       "     'index': 0,\n",
       "     'logprobs': None,\n",
       "     'message': {'content': 'Question: Where is Lunar landing happened the first time?\\nAnswer: The first Lunar landing happened on the Moon.',\n",
       "      'role': 'assistant',\n",
       "      'function_call': None,\n",
       "      'tool_calls': None}}],\n",
       "   'created': 1709530762,\n",
       "   'model': 'gpt-3.5-turbo-0125',\n",
       "   'object': 'chat.completion',\n",
       "   'system_fingerprint': 'fp_2b778c6b35',\n",
       "   'usage': {'completion_tokens': 22,\n",
       "    'prompt_tokens': 51,\n",
       "    'total_tokens': 73}},\n",
       "  'kwargs': {'stringify_request': '{\"temperature\": 0.0, \"max_tokens\": 150, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"n\": 1, \"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Given the fields `question`, produce the fields `answer`.\\\\n\\\\n---\\\\n\\\\nFollow the following format.\\\\n\\\\nQuestion: ${question}\\\\nAnswer: ${answer}\\\\n\\\\n---\\\\n\\\\nQuestion: WHere is Lunar landing happend the first time?\\\\nAnswer:\"}]}'},\n",
       "  'raw_kwargs': {}},\n",
       " {'prompt': 'Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: WHere is Lunar landing happend the first time?\\nAnswer:',\n",
       "  'response': {'id': 'chatcmpl-8yvKkXsAN5lNoKIrXwpL5P9j23jd2',\n",
       "   'choices': [{'finish_reason': 'stop',\n",
       "     'index': 0,\n",
       "     'logprobs': None,\n",
       "     'message': {'content': 'Question: Where is Lunar landing happened the first time?\\nAnswer: The first Lunar landing happened on the Moon.',\n",
       "      'role': 'assistant',\n",
       "      'function_call': None,\n",
       "      'tool_calls': None}}],\n",
       "   'created': 1709530762,\n",
       "   'model': 'gpt-3.5-turbo-0125',\n",
       "   'object': 'chat.completion',\n",
       "   'system_fingerprint': 'fp_2b778c6b35',\n",
       "   'usage': {'completion_tokens': 22,\n",
       "    'prompt_tokens': 51,\n",
       "    'total_tokens': 73}},\n",
       "  'kwargs': {'stringify_request': '{\"temperature\": 0.0, \"max_tokens\": 150, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"n\": 1, \"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Given the fields `question`, produce the fields `answer`.\\\\n\\\\n---\\\\n\\\\nFollow the following format.\\\\n\\\\nQuestion: ${question}\\\\nAnswer: ${answer}\\\\n\\\\n---\\\\n\\\\nQuestion: WHere is Lunar landing happend the first time?\\\\nAnswer:\"}]}'},\n",
       "  'raw_kwargs': {}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: WHere is Lunar landing happend the first time?\n",
      "Answer:\u001b[32m Question: Where is Lunar landing happened the first time?\n",
      "Answer: The first Lunar landing happened on the Moon.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But can you tell me Why DSPy?\n",
    "\n",
    "- Streamline the process of prompt-engineering with input and objective \n",
    "\n",
    "- Create Modules of LMs that can work to achieve objective \n",
    "\n",
    "- Then train the modules by using Datasets built by hand, and with LLMs \n",
    "\n",
    "- Evalute the modules with the Metrics that is custom coded in DSPy\n",
    "\n",
    "- Including Fine-tuning smaller models like T5 and Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whats in Next Video? \n",
    "- Can you tell me How to configure LMs in DSPy \n",
    "  OpenAI, HF_Models, Ollama_models\n",
    "\n",
    "- Can you show some tasks we can perform with these models?\n",
    "    Creating a minimal code example to show how the models \n",
    "perform on QA, Classification and Summarisation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
